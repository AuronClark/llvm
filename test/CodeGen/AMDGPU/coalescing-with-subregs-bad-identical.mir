# RUN: llc -mtriple=amdgcn--amdpal -mcpu=gfx803 -run-pass=simple-register-coalescing -o - %s | FileCheck -check-prefix=GCN %s

# With one version of the D48102 fix, this test failed with
# Assertion failed: (Id != S.end() && T != S.end() && T->valno == Id->valno), function pruneSubRegValues, file ../lib/CodeGen/RegisterCoalescer.cpp, line 2870.

# GCN: {{^body}}

--- |
  ; ModuleID = 'cutdown.ll'
  source_filename = "cutdown.ll"
  target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5"
  target triple = "amdgcn--amdpal"
  
  ; Function Attrs: nounwind readnone speculatable
  declare float @llvm.minnum.f32(float, float) #0
  
  ; Function Attrs: nounwind
  define dllexport amdgpu_cs void @_amdgpu_cs_main(<3 x i32> %arg) local_unnamed_addr #1 !spirv.ExecutionModel !1 {
  .entry:
    br i1 undef, label %bb, label %Flow3, !amdgpu.uniform !2
  
  bb:                                               ; preds = %.entry
    br i1 undef, label %bb7, label %Flow2, !amdgpu.uniform !2
  
  bb7:                                              ; preds = %bb
    %tmp1 = extractelement <3 x i32> %arg, i32 0
    %tmp2 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 undef>, i32 %tmp1, i32 0
    %tmp3 = insertelement <4 x i32> %tmp2, i32 undef, i32 1
    %tmp4 = call <4 x float> @llvm.amdgcn.image.load.v4f32.v4i32.v8i32(<4 x i32> %tmp3, <8 x i32> undef, i32 15, i1 false, i1 false, i1 false, i1 false) #6
    %tmp5 = extractelement <4 x float> %tmp4, i32 0
    %tmp6 = bitcast float %tmp5 to i32
    %tmp8 = insertelement <4 x i32> undef, i32 %tmp6, i32 0
    %tmp9 = shufflevector <4 x i32> %tmp8, <4 x i32> undef, <4 x i32> zeroinitializer
    %tmp10 = bitcast <4 x i32> %tmp9 to <4 x float>
    %tmp11 = fmul reassoc nnan arcp contract <4 x float> %tmp10, zeroinitializer
    %tmp12 = fadd reassoc nnan arcp contract <4 x float> %tmp11, zeroinitializer
    %tmp15 = bitcast <4 x float> %tmp12 to <4 x i32>
    %tmp16 = shufflevector <4 x i32> %tmp15, <4 x i32> undef, <3 x i32> <i32 3, i32 3, i32 3>
    %tmp17 = bitcast <3 x i32> %tmp16 to <3 x float>
    %x2.i = extractelement <3 x float> %tmp17, i32 2
    %tmp18 = fdiv float 1.000000e+00, %x2.i
    %tmp19 = fmul float 0.000000e+00, %tmp18
    %tmp20 = bitcast float %tmp19 to i32
    %tmp21 = insertelement <3 x i32> undef, i32 %tmp20, i32 0
    %tmp22 = shufflevector <3 x i32> %tmp21, <3 x i32> undef, <3 x i32> zeroinitializer
    %tmp23 = bitcast <3 x i32> %tmp22 to <3 x float>
    %tmp24 = fmul reassoc nnan arcp contract <3 x float> zeroinitializer, %tmp23
    %tmp25 = fadd reassoc nnan arcp contract <3 x float> %tmp24, zeroinitializer
    %tmp26 = bitcast <3 x float> %tmp25 to <3 x i32>
    %tmp27 = shufflevector <3 x i32> %tmp26, <3 x i32> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 undef>
    br i1 undef, label %.lr.ph5605, label %Flow, !amdgpu.uniform !2
  
  .lr.ph5605:                                       ; preds = %bb7
    %bc5216 = bitcast <4 x i32> %tmp27 to <4 x float>
    %tmp28 = extractelement <4 x float> %bc5216, i32 0
    %tmp29 = fmul reassoc nnan arcp contract float %tmp28, 0.000000e+00
    %tmp30 = fadd reassoc nnan arcp contract float %tmp29, 0.000000e+00
    %tmp32 = tail call float @llvm.minnum.f32(float %tmp30, float 1.000000e+00) #6
    %tmp33 = fcmp une float %tmp32, 1.000000e+00
    %tmp36 = select i1 %tmp33, i32 2143289344, i32 0
    %tmp37 = bitcast i32 %tmp36 to float
    %tmp38 = fcmp ogt float %tmp37, 0.000000e+00
    %0 = call { i1, i64 } @llvm.amdgcn.if(i1 %tmp38)
    %1 = extractvalue { i1, i64 } %0, 0
    %2 = extractvalue { i1, i64 } %0, 1
    br i1 %1, label %bb39, label %._crit_edge5606
  
  bb39:                                             ; preds = %.lr.ph5605
    br i1 undef, label %bb40, label %._crit_edge5606, !structurizecfg.uniform !2, !amdgpu.uniform !2
  
  bb40:                                             ; preds = %bb39
    br label %._crit_edge5606, !structurizecfg.uniform !2
  
  Flow:                                             ; preds = %._crit_edge5606, %bb7
    %3 = phi <4 x i32> [ %__llpc_global_proxy_r4.12.vec.insert3549, %._crit_edge5606 ], [ undef, %bb7 ]
    %4 = phi i1 [ false, %._crit_edge5606 ], [ true, %bb7 ]
    br i1 %4, label %.lr.ph5583, label %Flow1, !amdgpu.uniform !2
  
  ._crit_edge5606:                                  ; preds = %.lr.ph5605, %bb39, %bb40
    call void @llvm.amdgcn.end.cf(i64 %2)
    %__llpc_global_proxy_r4.12.vec.insert3549 = insertelement <4 x i32> %tmp27, i32 undef, i32 3
    br label %Flow
  
  .lr.ph5583:                                       ; preds = %Flow
    %__llpc_global_proxy_r4.12.vec.insert3399 = insertelement <4 x i32> %tmp27, i32 undef, i32 3
    br i1 undef, label %bb48, label %._crit_edge5584, !structurizecfg.uniform !2, !amdgpu.uniform !2
  
  bb48:                                             ; preds = %.lr.ph5583
    br label %._crit_edge5584, !structurizecfg.uniform !2
  
  Flow1:                                            ; preds = %bb50, %._crit_edge5584, %Flow
    %5 = phi <4 x i32> [ %__llpc_global_proxy_r4.3, %bb50 ], [ %__llpc_global_proxy_r4.3, %._crit_edge5584 ], [ %3, %Flow ]
    br label %bb56
  
  ._crit_edge5584:                                  ; preds = %.lr.ph5583, %bb48
    %__llpc_global_proxy_r4.3 = phi <4 x i32> [ %__llpc_global_proxy_r4.12.vec.insert3399, %.lr.ph5583 ], [ zeroinitializer, %bb48 ]
    br i1 undef, label %bb50, label %Flow1, !structurizecfg.uniform !2, !amdgpu.uniform !2
  
  bb50:                                             ; preds = %._crit_edge5584
    %tmp51 = load <4 x i32>, <4 x i32> addrspace(4)* undef, align 16
    br label %Flow1, !structurizecfg.uniform !2
  
  Flow2:                                            ; preds = %bb89, %bb
    br label %bb94
  
  bb56:                                             ; preds = %Flow1
    %__llpc_global_proxy_r4.4 = phi <4 x i32> [ %5, %Flow1 ]
    %bc5178 = bitcast <4 x i32> %__llpc_global_proxy_r4.4 to <4 x float>
    %tmp57 = extractelement <4 x float> %bc5178, i32 0
    %tmp58 = fmul reassoc nnan arcp contract float %tmp57, 0.000000e+00
    %tmp59 = fadd reassoc nnan arcp contract float %tmp58, 0.000000e+00
    %tmp60 = bitcast float %tmp59 to i32
    %tmp61 = insertelement <2 x i32> undef, i32 %tmp60, i32 1
    %tmp62 = bitcast <2 x i32> %tmp61 to <2 x float>
    %tmp63 = fmul reassoc nnan arcp contract <2 x float> zeroinitializer, %tmp62
    %tmp64 = fadd reassoc nnan arcp contract <2 x float> zeroinitializer, %tmp63
    %tmp65 = fmul reassoc nnan arcp contract <2 x float> %tmp64, <float 5.000000e-01, float -5.000000e-01>
    %tmp66 = fadd reassoc nnan arcp contract <2 x float> %tmp65, <float 5.000000e-01, float 5.000000e-01>
    %tmp67 = fmul reassoc nnan arcp contract <2 x float> %tmp66, zeroinitializer
    %tmp68 = fadd reassoc nnan arcp contract <2 x float> %tmp67, <float -5.000000e-01, float -5.000000e-01>
    %tmp69 = fptosi <2 x float> %tmp68 to <2 x i32>
    %tmp70 = extractelement <2 x i32> %tmp69, i32 1
    %tmp71 = call i32 @llvm.amdgcn.s.buffer.load.i32(<4 x i32> undef, i32 12, i1 false) #6
    %tmp72 = mul i32 %tmp70, %tmp71
    %tmp74 = shl i32 %tmp72, 2
    %tmp75 = call float @llvm.amdgcn.buffer.load.format.f32(<4 x i32> undef, i32 %tmp74, i32 0, i1 false, i1 false)
    %tmp76 = insertelement <4 x float> undef, float %tmp75, i64 0
    %bc5181 = bitcast <4 x float> %tmp76 to <4 x i32>
    %tmp77 = shufflevector <4 x i32> %bc5181, <4 x i32> zeroinitializer, <2 x i32> <i32 0, i32 4>
    %tmp78 = icmp ne <2 x i32> %tmp77, zeroinitializer
    %tmp79 = sext <2 x i1> %tmp78 to <2 x i32>
    %tmp80 = extractelement <2 x i32> %tmp79, i32 0
    %tmp82 = icmp eq i32 %tmp80, 0
    %6 = xor i1 %tmp82, true
    %7 = call { i1, i64 } @llvm.amdgcn.if(i1 %6)
    %8 = extractvalue { i1, i64 } %7, 0
    %9 = extractvalue { i1, i64 } %7, 1
    br i1 %8, label %bb83, label %bb89
  
  bb83:                                             ; preds = %bb56
    %tmp84 = call <4 x i32> @llvm.amdgcn.s.buffer.load.v4i32(<4 x i32> undef, i32 0, i1 false) #6
    br label %bb89
  
  bb89:                                             ; preds = %bb83, %bb56
    call void @llvm.amdgcn.end.cf(i64 %9)
    br label %Flow2
  
  Flow3:                                            ; preds = %bb94, %bb115, %.entry
    br label %bb121
  
  bb94:                                             ; preds = %Flow2
    br i1 undef, label %Flow3, label %bb95, !structurizecfg.uniform !2, !amdgpu.uniform !2
  
  bb95:                                             ; preds = %bb94
    br i1 undef, label %bb109, label %bb96, !structurizecfg.uniform !2, !amdgpu.uniform !2
  
  bb96:                                             ; preds = %bb95
    br i1 undef, label %._crit_edge, label %bb97, !structurizecfg.uniform !2, !amdgpu.uniform !2
  
  bb97:                                             ; preds = %bb96
    br i1 undef, label %bb98, label %._crit_edge, !structurizecfg.uniform !2, !amdgpu.uniform !2
  
  bb98:                                             ; preds = %bb97
    br label %._crit_edge, !structurizecfg.uniform !2
  
  ._crit_edge:                                      ; preds = %bb96, %bb97, %bb98
    br label %bb115, !structurizecfg.uniform !2
  
  bb109:                                            ; preds = %bb95
    br label %bb115, !structurizecfg.uniform !2
  
  bb115:                                            ; preds = %._crit_edge, %bb109
    br label %Flow3, !structurizecfg.uniform !2
  
  bb121:                                            ; preds = %Flow3
    ret void
  }
  
  ; Function Attrs: nounwind readonly
  declare <4 x float> @llvm.amdgcn.image.load.v4f32.v4i32.v8i32(<4 x i32>, <8 x i32>, i32, i1, i1, i1, i1) #2
  
  ; Function Attrs: nounwind readnone
  declare i32 @llvm.amdgcn.s.buffer.load.i32(<4 x i32>, i32, i1) #3
  
  ; Function Attrs: nounwind readnone
  declare <4 x i32> @llvm.amdgcn.s.buffer.load.v4i32(<4 x i32>, i32, i1) #3
  
  ; Function Attrs: nounwind readonly
  declare float @llvm.amdgcn.buffer.load.format.f32(<4 x i32>, i32, i32, i1, i1) #2
  
  ; Function Attrs: convergent nounwind
  declare { i1, i64 } @llvm.amdgcn.if(i1) #4
  
  ; Function Attrs: convergent nounwind
  declare { i1, i64 } @llvm.amdgcn.else(i64) #4
  
  ; Function Attrs: convergent nounwind readnone
  declare i64 @llvm.amdgcn.break(i64) #5
  
  ; Function Attrs: convergent nounwind readnone
  declare i64 @llvm.amdgcn.if.break(i1, i64) #5
  
  ; Function Attrs: convergent nounwind readnone
  declare i64 @llvm.amdgcn.else.break(i64, i64) #5
  
  ; Function Attrs: convergent nounwind
  declare i1 @llvm.amdgcn.loop(i64) #4
  
  ; Function Attrs: convergent nounwind
  declare void @llvm.amdgcn.end.cf(i64) #4
  
  ; Function Attrs: nounwind
  declare void @llvm.stackprotector(i8*, i8**) #6
  
  attributes #0 = { nounwind readnone speculatable "target-cpu"="gfx803" }
  attributes #1 = { nounwind "target-cpu"="gfx803" }
  attributes #2 = { nounwind readonly "target-cpu"="gfx803" }
  attributes #3 = { nounwind readnone "target-cpu"="gfx803" }
  attributes #4 = { convergent nounwind }
  attributes #5 = { convergent nounwind readnone }
  attributes #6 = { nounwind }
  
  !amdgpu.pal.metadata = !{!0}
  
  !0 = !{i32 268435482, i32 1, i32 268435488, i32 -1, i32 268435480, i32 411087283, i32 268435481, i32 425383423, i32 268435538, i32 64, i32 268435539, i32 0, i32 11794, i32 2883584, i32 11795, i32 6022, i32 11783, i32 16, i32 11784, i32 16, i32 11785, i32 1, i32 268435530, i32 0, i32 268435495, i32 0, i32 268435502, i32 0, i32 268435509, i32 256, i32 268435516, i32 104, i32 268435456, i32 1246098527, i32 268435457, i32 -1710647087, i32 11840, i32 268435456, i32 11842, i32 0}
  !1 = !{i32 5}
  !2 = !{}

...
---
name:            _amdgpu_cs_main
alignment:       0
exposesReturnsTwice: false
legalized:       false
regBankSelected: false
selected:        false
failedISel:      false
tracksRegLiveness: true
registers:       
  - { id: 0, class: sreg_128, preferred-register: '' }
  - { id: 1, class: sreg_64, preferred-register: '' }
  - { id: 2, class: sreg_128, preferred-register: '' }
  - { id: 3, class: vreg_1, preferred-register: '' }
  - { id: 4, class: sreg_128, preferred-register: '' }
  - { id: 5, class: sreg_128, preferred-register: '' }
  - { id: 6, class: sreg_128, preferred-register: '' }
  - { id: 7, class: sreg_128, preferred-register: '' }
  - { id: 8, class: sreg_128, preferred-register: '' }
  - { id: 9, class: sreg_64, preferred-register: '' }
  - { id: 10, class: vgpr_32, preferred-register: '' }
  - { id: 11, class: vgpr_32, preferred-register: '' }
  - { id: 12, class: vgpr_32, preferred-register: '' }
  - { id: 13, class: sreg_128, preferred-register: '' }
  - { id: 14, class: sreg_128, preferred-register: '' }
  - { id: 15, class: sreg_32_xm0, preferred-register: '' }
  - { id: 16, class: sreg_32_xm0, preferred-register: '' }
  - { id: 17, class: sreg_128, preferred-register: '' }
  - { id: 18, class: vgpr_32, preferred-register: '' }
  - { id: 19, class: sreg_32_xm0, preferred-register: '' }
  - { id: 20, class: sreg_32_xm0, preferred-register: '' }
  - { id: 21, class: sreg_128, preferred-register: '' }
  - { id: 22, class: sreg_32_xm0, preferred-register: '' }
  - { id: 23, class: sreg_32_xm0, preferred-register: '' }
  - { id: 24, class: sreg_32_xm0, preferred-register: '' }
  - { id: 25, class: sreg_32_xm0, preferred-register: '' }
  - { id: 26, class: sreg_256, preferred-register: '' }
  - { id: 27, class: vgpr_32, preferred-register: '' }
  - { id: 28, class: vreg_128, preferred-register: '' }
  - { id: 29, class: vgpr_32, preferred-register: '' }
  - { id: 30, class: vgpr_32, preferred-register: '' }
  - { id: 31, class: vgpr_32, preferred-register: '' }
  - { id: 32, class: vgpr_32, preferred-register: '' }
  - { id: 33, class: vgpr_32, preferred-register: '' }
  - { id: 34, class: vgpr_32, preferred-register: '' }
  - { id: 35, class: vgpr_32, preferred-register: '' }
  - { id: 36, class: vgpr_32, preferred-register: '' }
  - { id: 37, class: vgpr_32, preferred-register: '' }
  - { id: 38, class: vgpr_32, preferred-register: '' }
  - { id: 39, class: sreg_128, preferred-register: '' }
  - { id: 40, class: sreg_64, preferred-register: '' }
  - { id: 41, class: vgpr_32, preferred-register: '' }
  - { id: 42, class: vgpr_32, preferred-register: '' }
  - { id: 43, class: vgpr_32, preferred-register: '' }
  - { id: 44, class: vgpr_32, preferred-register: '' }
  - { id: 45, class: vgpr_32, preferred-register: '' }
  - { id: 46, class: sreg_64_xexec, preferred-register: '$vcc' }
  - { id: 47, class: vgpr_32, preferred-register: '' }
  - { id: 48, class: vgpr_32, preferred-register: '' }
  - { id: 49, class: vgpr_32, preferred-register: '' }
  - { id: 50, class: sreg_64, preferred-register: '$vcc' }
  - { id: 51, class: vgpr_32, preferred-register: '' }
  - { id: 52, class: sreg_64, preferred-register: '' }
  - { id: 53, class: sreg_64, preferred-register: '' }
  - { id: 54, class: sreg_64, preferred-register: '$vcc' }
  - { id: 55, class: sreg_128, preferred-register: '' }
  - { id: 56, class: sreg_32_xm0, preferred-register: '' }
  - { id: 57, class: sreg_128, preferred-register: '' }
  - { id: 58, class: vgpr_32, preferred-register: '' }
  - { id: 59, class: vgpr_32, preferred-register: '' }
  - { id: 60, class: vgpr_32, preferred-register: '' }
  - { id: 61, class: vgpr_32, preferred-register: '' }
  - { id: 62, class: vgpr_32, preferred-register: '' }
  - { id: 63, class: vgpr_32, preferred-register: '' }
  - { id: 64, class: vgpr_32, preferred-register: '' }
  - { id: 65, class: vgpr_32, preferred-register: '' }
  - { id: 66, class: vgpr_32, preferred-register: '' }
  - { id: 67, class: sreg_32_xm0_xexec, preferred-register: '' }
  - { id: 68, class: sreg_128, preferred-register: '' }
  - { id: 69, class: sreg_32_xm0, preferred-register: '' }
  - { id: 70, class: sreg_32, preferred-register: '' }
  - { id: 71, class: sreg_32_xm0, preferred-register: '' }
  - { id: 72, class: sreg_32_xm0, preferred-register: '' }
  - { id: 73, class: vgpr_32, preferred-register: '' }
  - { id: 74, class: vgpr_32, preferred-register: '' }
  - { id: 75, class: sreg_128, preferred-register: '' }
  - { id: 76, class: vgpr_32, preferred-register: '' }
  - { id: 77, class: sreg_64, preferred-register: '$vcc' }
  - { id: 78, class: vreg_128, preferred-register: '' }
  - { id: 79, class: vgpr_32, preferred-register: '' }
  - { id: 80, class: vgpr_32, preferred-register: '' }
  - { id: 81, class: vreg_128, preferred-register: '' }
  - { id: 82, class: vgpr_32, preferred-register: '' }
  - { id: 83, class: vgpr_32, preferred-register: '' }
  - { id: 84, class: vgpr_32, preferred-register: '' }
  - { id: 85, class: vreg_128, preferred-register: '' }
  - { id: 86, class: vreg_128, preferred-register: '' }
  - { id: 87, class: vreg_128, preferred-register: '' }
  - { id: 88, class: vreg_128, preferred-register: '' }
  - { id: 89, class: vreg_128, preferred-register: '' }
  - { id: 90, class: vreg_128, preferred-register: '' }
  - { id: 91, class: vreg_128, preferred-register: '' }
  - { id: 92, class: vreg_128, preferred-register: '' }
  - { id: 93, class: vgpr_32, preferred-register: '' }
  - { id: 94, class: vgpr_32, preferred-register: '' }
  - { id: 95, class: vreg_128, preferred-register: '' }
  - { id: 96, class: vreg_1, preferred-register: '' }
  - { id: 97, class: vreg_128, preferred-register: '' }
  - { id: 98, class: vreg_128, preferred-register: '' }
  - { id: 99, class: sreg_64, preferred-register: '' }
  - { id: 100, class: sreg_64, preferred-register: '' }
liveins:         
  - { reg: '$vgpr0', virtual-reg: '%10' }
  - { reg: '$vgpr1', virtual-reg: '%11' }
  - { reg: '$vgpr2', virtual-reg: '%12' }
frameInfo:       
  isFrameAddressTaken: false
  isReturnAddressTaken: false
  hasStackMap:     false
  hasPatchPoint:   false
  stackSize:       0
  offsetAdjustment: 0
  maxAlignment:    0
  adjustsStack:    false
  hasCalls:        false
  stackProtector:  ''
  maxCallFrameSize: 4294967295
  hasOpaqueSPAdjustment: false
  hasVAStart:      false
  hasMustTailInVarArgFunc: false
  localFrameSize:  0
  savePoint:       ''
  restorePoint:    ''
fixedStack:      
stack:           
constants:       
body:             |
  bb.0..entry:
    successors: %bb.1(0x40000000), %bb.20(0x40000000)
    liveins: $vgpr0, $vgpr1, $vgpr2
  
    %10:vgpr_32 = COPY killed $vgpr0
    S_CBRANCH_SCC1 %bb.20, implicit undef $scc
  
  bb.1.bb:
    successors: %bb.2(0x40000000), %bb.16(0x40000000)
  
    S_CBRANCH_SCC1 %bb.16, implicit undef $scc
  
  bb.2.bb7:
    successors: %bb.4(0x40000000), %bb.3(0x40000000)
  
    %20:sreg_32_xm0 = S_MOV_B32 0
    %83:vgpr_32 = V_MOV_B32_e32 0, implicit $exec
    undef %81.sub0:vreg_128 = COPY killed %10
    %81.sub2:vreg_128 = COPY killed %83
    undef %26.sub0:sreg_256 = COPY %20
    %26.sub1:sreg_256 = COPY %20
    %26.sub2:sreg_256 = COPY %20
    %26.sub3:sreg_256 = COPY %20
    %26.sub4:sreg_256 = COPY %20
    %26.sub5:sreg_256 = COPY %20
    %26.sub6:sreg_256 = COPY %20
    %26.sub7:sreg_256 = COPY killed %20
    %27:vgpr_32 = IMAGE_LOAD_V1_V4 killed %81, killed %26, 1, -1, 0, 0, 0, 0, 0, 0, implicit $exec :: (dereferenceable load 16 from constant-pool, addrspace 4)
    %31:vgpr_32 = V_MAD_F32 0, killed %27, 0, 0, 0, 0, 0, 0, implicit $exec
    %32:vgpr_32 = V_RCP_F32_e32 killed %31, implicit $exec
    %33:vgpr_32 = V_MUL_F32_e32 0, killed %32, implicit $exec
    %34:vgpr_32 = V_MAD_F32 0, killed %33, 0, 0, 0, 0, 0, 0, implicit $exec
    dead %35:vgpr_32 = V_MAC_F32_e32 undef %36:vgpr_32, undef %37:vgpr_32, undef %35, implicit $exec
    undef %85.sub0:vreg_128 = COPY %34
    %18:vgpr_32 = V_MOV_B32_e32 -1, implicit $exec
    S_CBRANCH_SCC0 %bb.4, implicit undef $scc
  
  bb.3:
    successors: %bb.6(0x80000000)
  
    %95:vreg_128 = IMPLICIT_DEF
    %96:vreg_1 = COPY killed %18
    S_BRANCH %bb.6
  
  bb.4..lr.ph5605:
    successors: %bb.5(0x40000000), %bb.7(0x40000000)
  
    %43:vgpr_32 = V_MAD_F32 0, killed %34, 0, 0, 0, 0, 0, 0, implicit $exec
    %45:vgpr_32 = V_MIN_F32_e32 1065353216, killed %43, implicit $exec
    %46:sreg_64_xexec = V_CMP_NEQ_F32_e64 0, 1065353216, 0, killed %45, 0, implicit $exec
    %47:vgpr_32 = V_MOV_B32_e32 2143289344, implicit $exec
    %49:vgpr_32 = V_CNDMASK_B32_e64 0, killed %47, killed %46, implicit $exec
    %50:sreg_64 = V_CMP_LT_F32_e64 0, 0, 0, killed %49, 0, implicit $exec
    %1:sreg_64 = COPY $exec, implicit-def $exec
    %99:sreg_64 = S_AND_B64 %1, %50, implicit-def dead $scc
    $exec = S_MOV_B64_term killed %99
    SI_MASK_BRANCH %bb.7, implicit $exec
    S_BRANCH %bb.5
  
  bb.5.bb39:
    successors: %bb.7(0x80000000)
  
    S_BRANCH %bb.7
  
  bb.6.Flow:
    successors: %bb.8(0x40000000), %bb.10(0x40000000)
  
    %3:vreg_1 = COPY killed %96
    %91:vreg_128 = COPY killed %95
    %54:sreg_64 = V_CMP_NE_U32_e64 0, killed %3, implicit $exec
    %53:sreg_64 = S_AND_B64 $exec, killed %54, implicit-def dead $scc
    $vcc = COPY killed %53
    %97:vreg_128 = COPY killed %91
    S_CBRANCH_VCCNZ %bb.8, implicit killed $vcc
    S_BRANCH %bb.10
  
  bb.7.._crit_edge5606:
    successors: %bb.6(0x80000000)
  
    $exec = S_OR_B64 $exec, killed %1, implicit-def $scc
    %51:vgpr_32 = V_MOV_B32_e32 0, implicit $exec
    %95:vreg_128 = COPY %85
    %96:vreg_1 = COPY killed %51
    S_BRANCH %bb.6
  
  bb.8..lr.ph5583:
    successors: %bb.9(0x40000000), %bb.11(0x40000000)
  
    %98:vreg_128 = COPY killed %85
    S_CBRANCH_SCC1 %bb.11, implicit undef $scc
    S_BRANCH %bb.9
  
  bb.9.bb48:
    successors: %bb.11(0x80000000)
  
    %56:sreg_32_xm0 = S_MOV_B32 0
    undef %57.sub0:sreg_128 = COPY %56
    %57.sub1:sreg_128 = COPY %56
    %57.sub2:sreg_128 = COPY %56
    %57.sub3:sreg_128 = COPY killed %56
    %55:sreg_128 = COPY killed %57
    %87:vreg_128 = COPY killed %55
    %98:vreg_128 = COPY killed %87
    S_BRANCH %bb.11
  
  bb.10.Flow1:
    successors: %bb.13(0x80000000)
  
    %88:vreg_128 = COPY killed %97
    S_BRANCH %bb.13
  
  bb.11.._crit_edge5584:
    successors: %bb.12(0x40000000), %bb.21(0x40000000)
  
    %86:vreg_128 = COPY killed %98
    S_CBRANCH_SCC0 %bb.12, implicit undef $scc
  
  bb.21:
    successors: %bb.10(0x80000000)
  
    %97:vreg_128 = COPY killed %86
    S_BRANCH %bb.10
  
  bb.12.bb50:
    successors: %bb.10(0x80000000)
  
    %97:vreg_128 = COPY killed %86
    S_BRANCH %bb.10
  
  bb.13.bb56:
    successors: %bb.14(0x40000000), %bb.15(0x40000000)
  
    %60:vgpr_32 = V_MAD_F32 0, killed %88.sub0, 0, target-flags(amdgpu-gotprel) 0, 0, 0, 0, 0, implicit $exec
    %61:vgpr_32 = V_MAD_F32 0, killed %60, 0, 0, 0, 0, 0, 0, implicit $exec
    %64:vgpr_32 = V_MAD_F32 0, killed %61, 0, -1090519040, 0, 1056964608, 0, 0, implicit $exec
    %65:vgpr_32 = V_MAD_F32 0, killed %64, 0, 0, 0, -1090519040, 0, 0, implicit $exec
    %66:vgpr_32 = V_CVT_I32_F32_e32 killed %65, implicit $exec
    %67:sreg_32_xm0_xexec = S_BUFFER_LOAD_DWORD_IMM undef %68:sreg_128, 12, 0 :: (dereferenceable invariant load 4)
    %93:vgpr_32 = V_MUL_LO_I32 killed %66, killed %67, implicit $exec
    %94:vgpr_32 = V_LSHLREV_B32_e32 2, killed %93, implicit $exec
    %73:vgpr_32 = BUFFER_LOAD_FORMAT_X_IDXEN killed %94, undef %75:sreg_128, 0, 0, 0, 0, 0, implicit $exec :: (dereferenceable load 4 from constant-pool, align 1, addrspace 4)
    %77:sreg_64 = V_CMP_NE_U32_e64 0, killed %73, implicit $exec
    %9:sreg_64 = COPY $exec, implicit-def $exec
    %100:sreg_64 = S_AND_B64 %9, %77, implicit-def dead $scc
    $exec = S_MOV_B64_term killed %100
    SI_MASK_BRANCH %bb.15, implicit $exec
    S_BRANCH %bb.14
  
  bb.14.bb83:
    successors: %bb.15(0x80000000)
  
  
  bb.15.bb89:
    successors: %bb.16(0x80000000)
  
    $exec = S_OR_B64 $exec, killed %9, implicit-def $scc
    S_BRANCH %bb.16
  
  bb.16.bb94:
    successors: %bb.20(0x40000000), %bb.17(0x40000000)
  
    S_CBRANCH_SCC1 %bb.20, implicit undef $scc
  
  bb.17.bb95:
    successors: %bb.18(0x40000000), %bb.19(0x40000000)
  
    S_CBRANCH_SCC1 %bb.18, implicit undef $scc
    S_BRANCH %bb.19
  
  bb.18.bb109:
    successors: %bb.19(0x80000000)
  
  
  bb.19.bb115:
    successors: %bb.20(0x80000000)
  
  
  bb.20.bb121:
    S_ENDPGM

...
